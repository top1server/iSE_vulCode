{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GatedGraphRecurrentLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, edge_types):\n",
    "        super(GatedGraphRecurrentLayer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.edge_types = edge_types\n",
    "        self.weight_matrices = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, hidden_dim, bias=True) for _ in range(edge_types)\n",
    "        ])\n",
    "        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, node_features, adjacency_matrices, num_steps):\n",
    "        h = node_features\n",
    "        for _ in range(num_steps):\n",
    "            aggregated_messages = []\n",
    "            for i, adjacency_matrix in enumerate(adjacency_matrices):\n",
    "                weighted_features = self.weight_matrices[i](h)\n",
    "                aggregated_message = torch.matmul(adjacency_matrix.T, weighted_features)\n",
    "                aggregated_messages.append(aggregated_message)\n",
    "            combined_message = torch.stack(aggregated_messages).sum(dim=0)\n",
    "            h = self.gru(combined_message, h)\n",
    "\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_conv_layers):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=1) for _ in range(num_conv_layers)\n",
    "        ])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, node_features):\n",
    "        node_features = node_features.unsqueeze(0).permute(0, 2, 1)\n",
    "        for conv in self.conv_layers:\n",
    "            node_features = F.relu(conv(node_features))\n",
    "            node_features = F.max_pool1d(node_features, kernel_size=node_features.size(2))\n",
    "        graph_features = node_features.view(-1)\n",
    "        output = self.mlp(graph_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphClassificationModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, edge_types, num_conv_layers, num_gru_steps):\n",
    "        super(GraphClassificationModel, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ggrl = GatedGraphRecurrentLayer(hidden_dim, edge_types)\n",
    "        self.conv = ConvLayer(hidden_dim, hidden_dim, num_conv_layers)\n",
    "        self.num_gru_steps = num_gru_steps\n",
    "\n",
    "    def forward(self, node_features, adjacency_matrices):\n",
    "        node_features = self.input_linear(node_features)\n",
    "        updated_node_features = self.ggrl(node_features, adjacency_matrices, self.num_gru_steps)\n",
    "        output = self.conv(updated_node_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, pkl_dir):\n",
    "        self.pkl_dir = pkl_dir\n",
    "        self.file_list = os.listdir(pkl_dir)\n",
    "        self.data_list = []\n",
    "        for filename in self.file_list:\n",
    "            batch_file = os.path.join(pkl_dir, filename)\n",
    "            with open(batch_file, 'rb') as f:\n",
    "                batch_data = pickle.load(f)\n",
    "                self.data_list.extend(batch_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pkl_dir = 'data/emb'\n",
    "dataset = Dataset(pkl_dir)\n",
    "train_indices, test_indices = train_test_split(\n",
    "    list(range(len(dataset))), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6912, Train Acc: 0.5563, Test Loss: 0.7059, Test Acc: 0.5200\n",
      "Epoch 2/10, Train Loss: 0.6864, Train Acc: 0.5637, Test Loss: 0.7129, Test Acc: 0.5200\n",
      "Epoch 3/10, Train Loss: 0.6874, Train Acc: 0.5637, Test Loss: 0.7048, Test Acc: 0.5200\n",
      "Epoch 4/10, Train Loss: 0.6865, Train Acc: 0.5637, Test Loss: 0.7005, Test Acc: 0.5200\n",
      "Epoch 5/10, Train Loss: 0.6864, Train Acc: 0.5625, Test Loss: 0.7032, Test Acc: 0.5200\n",
      "Epoch 6/10, Train Loss: 0.6862, Train Acc: 0.5637, Test Loss: 0.7008, Test Acc: 0.5200\n",
      "Epoch 7/10, Train Loss: 0.6859, Train Acc: 0.5637, Test Loss: 0.6975, Test Acc: 0.5200\n",
      "Epoch 8/10, Train Loss: 0.6858, Train Acc: 0.5637, Test Loss: 0.6975, Test Acc: 0.5200\n",
      "Epoch 9/10, Train Loss: 0.6857, Train Acc: 0.5637, Test Loss: 0.6989, Test Acc: 0.5200\n",
      "Epoch 10/10, Train Loss: 0.6859, Train Acc: 0.5637, Test Loss: 0.6983, Test Acc: 0.5200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = 768 + 8\n",
    "hidden_dim = 128\n",
    "edge_types = 3\n",
    "num_conv_layers = 5\n",
    "num_gru_steps = 5\n",
    "\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GraphClassificationModel(input_dim, hidden_dim, edge_types, num_conv_layers, num_gru_steps)\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for idx in range(len(train_dataset)):\n",
    "        optimizer.zero_grad()\n",
    "        sample = train_dataset[idx]\n",
    "        node_features = sample.x\n",
    "        label = sample.y.float()\n",
    "        adjacency_matrices = [sample.ast_adj_matrix, sample.cfg_adj_matrix, sample.pdg_adj_matrix]\n",
    "\n",
    "        node_features = node_features.to(device)\n",
    "        label = label.to(device)\n",
    "        adjacency_matrices = [adj.to(device).float() for adj in adjacency_matrices]\n",
    "        output = model(node_features, adjacency_matrices)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = torch.sigmoid(output).item() >= 0.5\n",
    "        correct = pred == label.item()\n",
    "        train_correct += int(correct)\n",
    "        train_total += 1\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(test_dataset)):\n",
    "            sample= test_dataset[idx]\n",
    "            node_features = sample.x\n",
    "            label = sample.y.float()\n",
    "            adjacency_matrices = [sample.ast_adj_matrix, sample.cfg_adj_matrix, sample.pdg_adj_matrix]\n",
    "\n",
    "            node_features = node_features.to(device)\n",
    "            label = label.to(device)\n",
    "            adjacency_matrices = [adj.to(device).float() for adj in adjacency_matrices]\n",
    "            output = model(node_features, adjacency_matrices)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            pred = torch.sigmoid(output).item() >= 0.5\n",
    "            correct = pred == label.item()\n",
    "            test_correct += int(correct)\n",
    "            test_total += 1\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss/train_total:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Test Loss: {test_loss/test_total:.4f}, Test Acc: {test_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
