{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pydot\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"D:\\\\iSE_vulCode\\\\data\\\\raw\\\\train.csv\")\n",
    "PATH_CODE = \"data/code/\"\n",
    "PATH_CPG = \"data/cpg/\"\n",
    "PATH_DOT = \"data/dot/\"\n",
    "PATH_JSON = \"data/json/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code(code):\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    code = re.sub(r'\\n\\s*\\n', '\\n', code).strip()\n",
    "    code = re.sub(r'\\s+\\(', '(', code)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_C_files(code, index, out_path):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    file_name = f\"{index}.c\"\n",
    "    with open(out_path + file_name, 'w') as f:\n",
    "        f.write(code)\n",
    "\n",
    "def to_DOT_files(code, index, out_path):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    file_name = f\"{index}.dot\"\n",
    "    with open(out_path + file_name, 'w') as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joern_parse(input_path, output_path, file_name):\n",
    "    out_file = file_name + \".bin\"\n",
    "    joern_parse_call = subprocess.run([\"joern-parse.bat\", input_path, \"--output\", output_path + out_file],\n",
    "                                      stdout=subprocess.PIPE, text=True, check=True)\n",
    "\n",
    "def joern_export(cpg_file_path, output_path, output_format=\"dot\"):\n",
    "    output_folder = output_path\n",
    "    joern_export_call = subprocess.run(\n",
    "        [\"joern-export.bat\", cpg_file_path, \"-o\", output_folder, \"--format\", output_format],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_codes = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    code = train_data.loc[i, 'code']\n",
    "    code = clean_code(code)\n",
    "    train_codes.append(code)\n",
    "    label = train_data.loc[i, 'Label']\n",
    "    train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dot(graph, function_name, file_name):\n",
    "    function = {\n",
    "        \"function\": function_name,\n",
    "        \"file\": file_name,\n",
    "        \"AST\": [],\n",
    "        \"CFG\": [],\n",
    "        \"PDG\": []\n",
    "    }\n",
    "\n",
    "    nodes = graph.get_nodes()\n",
    "    edges = graph.get_edges()\n",
    "\n",
    "    # Tạo từ điển cạnh để tra cứu nhanh\n",
    "    edge_dict = {}\n",
    "    for edge in edges:\n",
    "        src_id = edge.get_source().strip('\"')\n",
    "        dst_id = edge.get_destination().strip('\"')\n",
    "        label_code = edge.get_label().strip('\"').split(': ') if edge.get_label() else [\"None\"]\n",
    "        label = label_code[0]\n",
    "        code = label_code[1] if len(label_code) > 1 and label_code[1].strip() else \"None\"\n",
    "\n",
    "        # Ghi cạnh vào từ điển\n",
    "        if src_id not in edge_dict:\n",
    "            edge_dict[src_id] = []\n",
    "        if dst_id not in edge_dict:\n",
    "            edge_dict[dst_id] = []\n",
    "        \n",
    "        edge_dict[src_id].append({\n",
    "            \"in\": src_id,\n",
    "            \"out\": dst_id,\n",
    "            \"label\": label,\n",
    "            \"code\": code\n",
    "        })\n",
    "\n",
    "    for node in nodes:\n",
    "        node_id = node.get_name().strip('\"')\n",
    "        node_label = node.get_label().strip('<>').strip('\"') if node.get_label() else \"None\"\n",
    "        node_type_code = re.sub(r\"<SUB>.*\", \"\", node_label).split(',')\n",
    "\n",
    "        node_type = 'None'\n",
    "        node_code = 'None'\n",
    "\n",
    "        # Xử lý phân tích node_type_code\n",
    "        if len(node_type_code) == 2:\n",
    "            node_type = node_type_code[0].strip('(')\n",
    "            node_code = node_type_code[1][:-1]\n",
    "        elif len(node_type_code) == 1:\n",
    "            node_type = node_type_code[0].strip()\n",
    "        else:\n",
    "            if node_type_code[0] == \"BLOCK\":\n",
    "                node_type = node_type_code[0].strip('(')\n",
    "                node_code = node_type_code[1] + node_type_code[2][:-1]\n",
    "            else:\n",
    "                node_type = node_type_code[0].strip('(') + ' ' + node_type_code[1]\n",
    "                node_code = node_type_code[2][:-1]\n",
    "        node_data = {\n",
    "            \"id\": node_id,\n",
    "            \"edges\": [],\n",
    "            \"properties\": []\n",
    "        }\n",
    "        node_data[\"properties\"].append({\"type\": node_type, \"code\": node_code})\n",
    "\n",
    "        # Lấy các cạnh liên quan\n",
    "        related_edges = edge_dict.get(node_id, [])\n",
    "        for edge in related_edges:\n",
    "            edge_data = {\n",
    "                \"in\": edge[\"in\"],\n",
    "                \"out\": edge[\"out\"],\n",
    "                \"label\": edge[\"label\"],\n",
    "                \"code\": edge[\"code\"]\n",
    "            }\n",
    "            node_data[\"edges\"].append(edge_data)\n",
    "\n",
    "        # Phân loại node vào AST, CFG, hoặc PDG\n",
    "        is_ast = any(edge[\"label\"].startswith(\"AST\") for edge in related_edges)\n",
    "        is_cfg = any(edge[\"label\"].startswith(\"CFG\") for edge in related_edges)\n",
    "        is_pdg = any(edge[\"label\"].startswith(\"DDG\") for edge in related_edges)\n",
    "\n",
    "        if is_ast:\n",
    "            function[\"AST\"].append(node_data)\n",
    "        if is_cfg:\n",
    "            function[\"CFG\"].append(node_data)\n",
    "        if is_pdg:\n",
    "            function[\"PDG\"].append(node_data)\n",
    "\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code2cpg(index_code):\n",
    "    to_C_files(train_codes[index_code], index_code , PATH_CODE)\n",
    "    if os.path.exists(PATH_CODE) and os.path.isdir(PATH_CODE):\n",
    "        joern_parse(PATH_CODE, PATH_CPG, f\"{index_code}_cpg\")\n",
    "\n",
    "def cpg2dot(cpg_file_path):\n",
    "    joern_export(cpg_file_path, PATH_DOT)\n",
    "\n",
    "def dot2json(input_folder, index, output_folder):\n",
    "    output_json_path = f'data/{output_folder}/{index}.json'\n",
    "\n",
    "    json_output = {\n",
    "        \"functions\": []\n",
    "    }\n",
    "    dot_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.dot')]\n",
    "    for dot_file in dot_files:\n",
    "        file_path = os.path.join(input_folder, dot_file)\n",
    "        try:\n",
    "            # Đọc file .dot\n",
    "            graphs = pydot.graph_from_dot_file(file_path)\n",
    "            if not graphs:\n",
    "                print(f\"Không thể đọc đồ thị từ file .dot: {file_path}. Bỏ qua tệp này.\")\n",
    "                continue\n",
    "\n",
    "            graph = graphs[0]\n",
    "            subgraphs = graph.get_subgraphs()\n",
    "\n",
    "            # Nếu có subgraphs, mỗi subgraph là một function\n",
    "            if subgraphs:\n",
    "                for subgraph in subgraphs:\n",
    "                    function_label = subgraph.get_label().strip('\"') if subgraph.get_label() else \"unknown_function\"\n",
    "                    function = process_dot(subgraph, function_label, dot_file)\n",
    "                    json_output[\"functions\"].append(function)\n",
    "            else:\n",
    "                # Nếu không có subgraphs, coi toàn bộ đồ thị là một function\n",
    "                function_name = graph.get_name().strip('\"') or \"unknown_function\"\n",
    "                function = process_dot(graph, function_name, dot_file)\n",
    "                json_output[\"functions\"].append(function)\n",
    "\n",
    "            print(f\"Đã xử lý thành công tệp: {dot_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi khi xử lý file {file_path}: {e}\")\n",
    "\n",
    "    # Lưu kết quả ra tệp JSON\n",
    "    if json_output[\"functions\"]:\n",
    "        try:\n",
    "            with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(json_output, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"Chuyển đổi thành công! Kết quả đã được lưu vào '{output_json_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi khi ghi tệp JSON: {e}\")\n",
    "    else:\n",
    "        print(\"Không tìm thấy functions trong bất kỳ tệp .dot nào.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
