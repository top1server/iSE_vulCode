{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export CPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import html\n",
    "import pydot\n",
    "import torch\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"D:\\\\iSE_vulCode\\\\data\\\\raw\\\\train.csv\")\n",
    "PATH_CODE = \"data/code/\"\n",
    "PATH_CPG = \"data/cpg/\"\n",
    "PATH_DOT = \"data/dot\"\n",
    "PATH_JSON = \"data/json/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code(code):\n",
    "    code = re.sub(r'\"(.*?)\"', 'STRING', code)\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    code = re.sub(r'\\n\\s*\\n', '\\n', code).strip()\n",
    "    code = re.sub(r'\\s+\\(', '(', code)\n",
    "    code = code.replace('\"', '')\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_C_files(code, index, out_path):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    file_name = f\"{index}.c\"\n",
    "    with open(out_path + file_name, 'w') as f:\n",
    "        f.write(code)\n",
    "\n",
    "def to_DOT_files(code, index, out_path):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    file_name = f\"{index}.dot\"\n",
    "    with open(out_path + file_name, 'w') as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joern_parse(input_path, output_path, file_name):\n",
    "    out_file = file_name + \".bin\"\n",
    "    joern_parse_call = subprocess.run(\n",
    "        [\"joern-parse.bat\",\n",
    "        input_path,\n",
    "        \"--output\",\n",
    "        output_path + out_file],\n",
    "        stdout=subprocess.PIPE,\n",
    "        text=True, \n",
    "        check=True)\n",
    "    return joern_parse_call.stdout\n",
    "\n",
    "def joern_export(index, output_dir, output_format=\"dot\"):\n",
    "    joern_export_command = [\n",
    "        \"joern-export.bat\",\n",
    "        \"--repr=all\",\n",
    "        f\"{PATH_CPG}{index}_cpg.bin\",\n",
    "        \"-o\",\n",
    "        output_dir,\n",
    "        \"--format\",\n",
    "        output_format\n",
    "    ]\n",
    "    joern_export_call = subprocess.run(\n",
    "        joern_export_command,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    default_output_file = os.path.join(output_dir, f\"export.dot\")\n",
    "    custom_output_file = os.path.join(output_dir, f\"{index}.dot\")\n",
    "    shutil.move(default_output_file, custom_output_file)\n",
    "    return joern_export_call.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_codes = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    code = train_data.loc[i, 'func']\n",
    "    code = clean_code(code)\n",
    "    train_codes.append(code)\n",
    "    label = train_data.loc[i, 'target']\n",
    "    train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code2cpg(index_code):\n",
    "    to_C_files(train_codes[index_code], index_code , PATH_CODE)\n",
    "    if os.path.exists(PATH_CODE) and os.path.isdir(PATH_CODE):\n",
    "        joern_parse(PATH_CODE, PATH_CPG, f\"{index_code}_cpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[INFO ] initialising from existing storage (d:\\\\iSE_vulCode\\\\data\\\\cpg\\\\0_cpg.bin)\\nexported 233 nodes, 1405 edges into d:\\\\iSE_vulCode\\\\data\\\\dot\\n[INFO ] closing graph: writing to storage at `d:\\\\iSE_vulCode\\\\data\\\\cpg\\\\0_cpg.bin`\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "code2cpg(i)\n",
    "joern_export(0, PATH_DOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import json\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(input_path):\n",
    "    graphs = pydot.graph_from_dot_file(input_path)\n",
    "    return graphs[0]\n",
    "\n",
    "def get_type(node):\n",
    "    attributes = node.get_attributes()\n",
    "    return attributes.get(\"TYPE_FULL_NAME\")[1:-1]\n",
    "\n",
    "def has_type(node):\n",
    "    attributes = node.get_attributes()\n",
    "    return \"TYPE_FULL_NAME\" in attributes\n",
    "\n",
    "def has_code(node):\n",
    "    attributes = node.get_attributes()\n",
    "    return \"CODE\" in attributes\n",
    "\n",
    "def get_code(node):\n",
    "    if has_code(node):\n",
    "        code = node.get_attributes()['CODE'][1:-1]\n",
    "        if has_type(node) and not get_type(node) == \"ANY\" and get_type(node) not in code:\n",
    "            code = f\"{get_type(node)} {code}\"\n",
    "        return code\n",
    "    return None\n",
    "    \n",
    "def has_line_number(node):\n",
    "    attributes = node.get_attributes()\n",
    "    return 'LINE_NUMBER' in attributes\n",
    "\n",
    "def get_line_number(node):\n",
    "    if has_line_number(node):\n",
    "        return node.get_attributes()['LINE_NUMBER']\n",
    "    return None\n",
    "\n",
    "def has_column_number(node):\n",
    "    attributes = node.get_attributes()\n",
    "    return 'COLUMN_NUMBER' in attributes\n",
    "\n",
    "def get_column_number(node):\n",
    "    if has_column_number(node):\n",
    "        return node.get_attributes()['COLUMN_NUMBER']\n",
    "    return None\n",
    "\n",
    "def get_method_full_name(node):\n",
    "    attributes = node.get_attributes()\n",
    "    if 'METHOD_FULL_NAME' in attributes:\n",
    "        return attributes['METHOD_FULL_NAME'][1:-1]\n",
    "    return None\n",
    "\n",
    "def get(node):\n",
    "    return node.get_attributes()\n",
    "\n",
    "def get_operator(node):\n",
    "    value = node.get_attributes()['METHOD_FULL_NAME']\n",
    "    if value is None:\n",
    "        return value\n",
    "    if (\"<operator>\" in value) or (\"<operators>\" in value):\n",
    "        return value.split(\".\")[-1][:-1] \n",
    "    return None\n",
    "\n",
    "def get_label(node):\n",
    "    label = node.get_attributes()['label']\n",
    "    if label == \"CALL\":\n",
    "        if get_method_full_name(node).startswith(\"<operator\"):\n",
    "            label = get_operator(node)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nodes(nodes):\n",
    "    ast_nodes = []\n",
    "    for node in nodes:\n",
    "        attributes = node.get_attributes()\n",
    "        if all(key in attributes for key in ['LINE_NUMBER', 'CODE', 'COLUMN_NUMBER']):\n",
    "            if attributes['label'] not in ['COMMENT', 'UNKNOWN'] and attributes['CODE'] not in ['\"<empty>\"', '\"<global>\"']:\n",
    "                ast_nodes.append(node)\n",
    "    return ast_nodes\n",
    "\n",
    "def order_nodes(nodes, max_nodes=500):\n",
    "    nodes_by_column = sorted(nodes, key=lambda node: get_column_number(node))\n",
    "    sorted_nodes = sorted(nodes_by_column, key=lambda node: get_line_number(node))\n",
    "    for i, node in enumerate(sorted_nodes):\n",
    "        setattr(node, 'order', i)\n",
    "    if len(sorted_nodes) > max_nodes:\n",
    "        return sorted_nodes[:max_nodes]\n",
    "    return sorted_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_labels = [\"BLOCK\", \"CALL\", \"COMMENT\", \"CONTROL_STRUCTURE\", \"FILE\", \"IDENTIFIER\", \"FIELD_IDENTIFIER\", \"LITERAL\",\n",
    "               \"LOCAL\", \"MEMBER\", \"METADATA\", \"METHOD\", \"METHODINST\", \"METHOD_PARAMETER_IN\", \"METHOD_PARAMETER_OUT\",\n",
    "               \"METHOD_RETURN\", \"NAMESPACE\", \"NAMESPACE_BLOCK\", \"RETURN\", \"TYPE\", \"TYPEDECL\", \"UNKNOWN\", \"JUMP_TARGET\"]\n",
    "\n",
    "operators = ['addition', 'addressOf', 'and', 'arithmeticShiftRight', 'assignment',\n",
    "             'assignmentAnd', 'assignmentArithmeticShiftRight', 'assignmentDivision',\n",
    "             'assignmentMinus', 'assignmentMultiplication', 'assignmentOr', 'assignmentPlus',\n",
    "             'assignmentShiftLeft', 'assignmentXor', 'cast', 'conditionalExpression',\n",
    "             'division', 'equals', 'fieldAccess', 'greaterEqualsThan', 'greaterThan',\n",
    "             'indirectFieldAccess', 'indirectIndexAccess', 'indirection', 'lessEqualsThan',\n",
    "             'lessThan', 'logicalAnd', 'logicalNot', 'logicalOr', 'minus', 'modulo', 'multiplication',\n",
    "             'not', 'notEquals', 'or', 'postDecrement', 'plus', 'postIncrement', 'preDecrement',\n",
    "             'preIncrement', 'shiftLeft', 'sizeOf', 'subtraction', 'pointerCall', 'alloc', 'expressionList',\n",
    "             'conditional', 'arrayInitializer', 'xor', 'op_ellipses', 'assignmentModulo', 'bracketedPrimary']\n",
    "\n",
    "node_labels += operators\n",
    "node_labels = {label: i for i, label in enumerate(node_labels)}\n",
    "node_labels['bracketedPrimary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_edges(nodes, edges):\n",
    "    valid_edges = []\n",
    "    node_ids = set(node.get_name() for node in nodes)\n",
    "    for edge in edges:\n",
    "        src = edge.get_source()\n",
    "        dst = edge.get_destination()\n",
    "        if src in node_ids and dst in node_ids:\n",
    "            valid_edges.append(edge)\n",
    "    return valid_edges\n",
    "\n",
    "def get_nodes_edges(input_path):\n",
    "    graph = get_graph(input_path)\n",
    "    nodes = filter_nodes(graph.get_nodes())\n",
    "    nodes = order_nodes(nodes)\n",
    "    edges = filter_edges(nodes, graph.get_edges())\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class NodesEmbedding:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.node_type_embedding = nn.Embedding(75, 16).to(self.device)\n",
    "\n",
    "    def __call__(self, nodes):\n",
    "        embedded_nodes = self.embed_nodes(nodes)\n",
    "        nodes_tensor = torch.tensor(embedded_nodes).float().to(self.device)\n",
    "        self.target = torch.zeros(nodes_tensor.size(0), nodes_tensor.size(1)).float().to(self.device)\n",
    "        self.target[:nodes_tensor.size(0), :] = nodes_tensor\n",
    "        return self.target\n",
    "\n",
    "    def embed_nodes(self, nodes):\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for node in nodes:\n",
    "                node_code = get_code(node)\n",
    "                input_ids, attention_mask = encode_input(node_code, self.tokenizer)\n",
    "                cls_feats = self.bert(input_ids.to(self.device), attention_mask.to(self.device))[0][:, 0]\n",
    "                source_embedding = torch.mean(cls_feats, dim=0)\n",
    "                node_type = get_label(node)\n",
    "                type_embedding = self.node_type_embedding(torch.tensor(node_labels[node_type]).to(self.device))\n",
    "                embedding = torch.cat((type_embedding, source_embedding), dim=0).cpu().numpy()\n",
    "                embeddings.append(embedding)\n",
    "        return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphsEmbedding:\n",
    "    def __init__(self, edge_type):\n",
    "        self.edge_type = edge_type\n",
    "\n",
    "    def __call__(self, nodes, edges):\n",
    "        adj_matrix = self.get_adj_matrix(nodes, edges)\n",
    "        return torch.tensor(adj_matrix, dtype=torch.long)\n",
    "\n",
    "    def get_adj_matrix(self, nodes, edges):\n",
    "        node_order = {node.get_name(): node.order for node in nodes}\n",
    "        n = len(node_order)\n",
    "        adjacency_matrix = [[0] * n for _ in range(n)]\n",
    "\n",
    "        for edge in edges:\n",
    "            edge_label = edge.get_label()\n",
    "            if self.edge_type == 'PDG' and edge_label not in {'CDG', 'DDG'}:\n",
    "                continue\n",
    "            if self.edge_type != 'PDG' and edge_label != self.edge_type:\n",
    "                continue\n",
    "            src_id, dst_id = edge.get_source(), edge.get_destination()\n",
    "            if src_id in node_order and dst_id in node_order:\n",
    "                in_order, out_order = node_order[src_id], node_order[dst_id]\n",
    "                if in_order is not None and out_order is not None:\n",
    "                    adjacency_matrix[in_order][out_order] = 1\n",
    "\n",
    "        return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_to_input(nodes, edges, target, nodes_embedding):\n",
    "    label = torch.tensor([target]).long()\n",
    "\n",
    "    ast = GraphsEmbedding('AST')\n",
    "    cfg = GraphsEmbedding('CFG')\n",
    "    pdg = GraphsEmbedding('PDG')\n",
    "\n",
    "    ast_adj_matrix = ast(nodes, edges)\n",
    "    cfg_adj_matrix = cfg(nodes, edges)\n",
    "    pdg_adj_matrix = pdg(nodes, edges)\n",
    "\n",
    "    return Data(x = nodes_embedding(nodes),\n",
    "                ast_adj_matrix = ast_adj_matrix,\n",
    "                cfg_adj_matrix = cfg_adj_matrix,\n",
    "                pdg_adj_matrix = pdg_adj_matrix,\n",
    "                y=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "output_dir = \"data/emb\"\n",
    "BATCH_SIZE = 50\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "nodes_embedding = NodesEmbedding()\n",
    "for batch_idx in range(0, 400):\n",
    "    batch_embeddings = []\n",
    "    start_code_idx = batch_idx * BATCH_SIZE\n",
    "    end_code_idx = (batch_idx + 1) * BATCH_SIZE\n",
    "\n",
    "    for index in range(start_code_idx, end_code_idx):\n",
    "        print(index)\n",
    "        code2cpg(index)\n",
    "        joern_export(index, PATH_DOT)\n",
    "        file_path = f\"data/dot/{index}.dot\"\n",
    "        nodes, edges = get_nodes_edges(file_path)\n",
    "        label = train_labels[index]\n",
    "        embed = nodes_to_input(nodes, edges, label, nodes_embedding)\n",
    "        batch_embeddings.append(embed)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        del embed, nodes, edges\n",
    "        shutil.rmtree(PATH_CODE)\n",
    "        shutil.rmtree(PATH_DOT)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_file = os.path.join(output_dir, f\"batch_{batch_idx}.pkl\")\n",
    "    with open(batch_file, \"wb\") as f:\n",
    "        pickle.dump(batch_embeddings, f)\n",
    "    print(f\"Saved batch {batch_idx} to {batch_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
